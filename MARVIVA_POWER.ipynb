{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las dos hojas (pestañas) del archivo Excel en DataFrames\n",
    "df_sheet1 = pd.read_excel('FORMATO_F2/S123_1d13c7d5527249ef82380603fdb7c7b9_EXCEL.xlsx', sheet_name='F2___MPP_XCaptura_y_Esfuerz_0')  # Cambia 'Hoja1' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F2/S123_1d13c7d5527249ef82380603fdb7c7b9_EXCEL.xlsx', sheet_name='example51_1')  # Cambia 'Hoja2' por el nombre real de la pestaña\n",
    "\n",
    "# Realizar la unión utilizando la columna llave\n",
    "df_merged = pd.merge(df_sheet1, df_sheet2, left_on='GlobalID', right_on='ParentGlobalID', how='inner')  # Cambia 'inner' por 'outer' si es necesario\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "df_merged.to_excel('F2_MPP-archivo_integrado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORMATO - F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las dos hojas (pestañas) del archivo Excel en DataFrames\n",
    "df_sheet1 = pd.read_excel('FORMATO_F3/S123_0f0d1cb917be491fb9b2dc327818f1e5_EXCEL.xlsx', sheet_name='F3___MPP_XLongitudes_de_Cap_0')  # Cambia 'Hoja1' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F3/S123_0f0d1cb917be491fb9b2dc327818f1e5_EXCEL.xlsx', sheet_name='example28_1')  # Cambia 'Hoja2' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F3/S123_0f0d1cb917be491fb9b2dc327818f1e5_EXCEL.xlsx', sheet_name='example31_2')\n",
    "\n",
    "# Realizar la unión utilizando la columna llave\n",
    "df_merged = pd.merge(df_sheet1, df_sheet2, left_on='GlobalID', right_on='ParentGlobalID', how='inner')  # Cambia 'inner' por 'outer' si es necesario\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "df_merged.to_excel('F3_MPP-archivo_integrado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORMATO - F4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las dos hojas (pestañas) del archivo Excel en DataFrames\n",
    "df_sheet1 = pd.read_excel('FORMATO_F4/S123_a64916fd8baf4d1f9fbe9d842000562c_EXCEL.xlsx', sheet_name='F4____MPP_XDias_efectivos_d_0')  # Cambia 'Hoja1' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F4/S123_a64916fd8baf4d1f9fbe9d842000562c_EXCEL.xlsx', sheet_name='example42_1')  # Cambia 'Hoja2' por el nombre real de la pestaña\n",
    "\n",
    "# Realizar la unión utilizando la columna llave\n",
    "df_merged = pd.merge(df_sheet1, df_sheet2, left_on='GlobalID', right_on='ParentGlobalID', how='inner')  # Cambia 'inner' por 'outer' si es necesario\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "df_merged.to_excel('F4_MPP-archivo_integrado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORMATO - F5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las dos hojas (pestañas) del archivo Excel en DataFrames\n",
    "df_sheet1 = pd.read_excel('FORMATO_F5/S123_84f41ef89d2f454ba996b07650a0ff89_EXCEL.xlsx', sheet_name='F5___MPP_XActividad_Diaria__0')  # Cambia 'Hoja1' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F5/S123_84f41ef89d2f454ba996b07650a0ff89_EXCEL.xlsx', sheet_name='example7_1')  # Cambia 'Hoja2' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F5/S123_84f41ef89d2f454ba996b07650a0ff89_EXCEL.xlsx', sheet_name='example9_2')\n",
    "\n",
    "# Realizar la unión utilizando la columna llave\n",
    "df_merged = pd.merge(df_sheet1, df_sheet2, left_on='GlobalID', right_on='ParentGlobalID', how='inner')  # Cambia 'inner' por 'outer' si es necesario\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "df_merged.to_excel('F5_MPP-archivo_integrado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORMATO - F6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las dos hojas (pestañas) del archivo Excel en DataFrames\n",
    "df_sheet1 = pd.read_excel('FORMATO_F6/S123_6ff515b3d0ad4213ae3d04d36daa3570_EXCEL.xlsx', sheet_name='BETA___Formulario_MPP_Conte_0')  # Cambia 'Hoja1' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F6/S123_6ff515b3d0ad4213ae3d04d36daa3570_EXCEL.xlsx', sheet_name='example42_1')  # Cambia 'Hoja2' por el nombre real de la pestaña\n",
    "df_sheet2 = pd.read_excel('FORMATO_F6/S123_6ff515b3d0ad4213ae3d04d36daa3570_EXCEL.xlsx', sheet_name='example13_2')\n",
    "\n",
    "# Realizar la unión utilizando la columna llave\n",
    "df_merged = pd.merge(df_sheet1, df_sheet2, left_on='GlobalID', right_on='ParentGlobalID', how='inner')  # Cambia 'inner' por 'outer' si es necesario\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "df_merged.to_excel('F6_MPP-archivo_integrado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AÑO ANTERIOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSOLIDACION BASES DIGITADORAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'Unnamed: 6_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     df_hoja \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path, sheet_name\u001b[38;5;241m=\u001b[39mhoja)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Unificar con la hoja base usando la columna en común ('nombre_x')\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     df_base \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_hoja\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumna_codigo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Mostrar los primeros registros del DataFrame unificado\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_base\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\Eduardo Gutierez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Eduardo Gutierez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\Eduardo Gutierez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:837\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    834\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[0;32m    835\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[1;32m--> 837\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    846\u001b[0m         join_index,\n\u001b[0;32m    847\u001b[0m         left_indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    852\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    853\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Eduardo Gutierez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2697\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2695\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[1;32m-> 2697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   2698\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2699\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2700\u001b[0m     )\n\u001b[0;32m   2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[1;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'Unnamed: 6_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo Excel\n",
    "file_path = 'DATA_MPP/Paola/MPP Colombia F3.xlsx'\n",
    "\n",
    "# Cargar todas las hojas de un archivo Excel en un diccionario de DataFrames\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Leer la primera hoja como base (supongamos que tiene los valores principales de 'nombre_x')\n",
    "df_base = pd.read_excel(file_path, sheet_name=xls.sheet_names[0])\n",
    "\n",
    "# Nombre de la columna que será usada como referencia (la que contiene el código común)\n",
    "columna_codigo = 'C01'\n",
    "\n",
    "# Iterar sobre las demás hojas para hacer el merge usando la columna 'nombre_x'\n",
    "for hoja in xls.sheet_names[1:]:\n",
    "    # Leer cada hoja\n",
    "    df_hoja = pd.read_excel(file_path, sheet_name=hoja)\n",
    "    \n",
    "    # Unificar con la hoja base usando la columna en común ('nombre_x')\n",
    "    df_base = pd.merge(df_base, df_hoja, on=columna_codigo, how='inner')\n",
    "\n",
    "# Mostrar los primeros registros del DataFrame unificado\n",
    "print(df_base.head())\n",
    "\n",
    "# Guardar los datos unificados en un nuevo archivo Excel\n",
    "df_base.to_excel('F3 MPP_archivo_unificado_Paola.xlsx', index=False)\n",
    "\n",
    "print(\"Datos guardados exitosamente en 'F3 MPP_archivo_unificado_Paola.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         C01  C02.1  C02.2   C02.3  C03  C04   C05  C06.1  C06.2  C07-Día  \\\n",
      "0  21-F6-001   27.0    3.0  2023.0  9.0  2.0  21.0    4.0    2.0      NaN   \n",
      "1  21-F6-001   27.0    3.0  2023.0  9.0  2.0  21.0    4.0    2.0      NaN   \n",
      "2  21-F6-002   15.0    3.0  2023.0  9.0  2.0  21.0    2.0    2.0      NaN   \n",
      "3  21-F6-002   15.0    3.0  2023.0  9.0  2.0  21.0    2.0    2.0      NaN   \n",
      "4  21-F6-002   15.0    3.0  2023.0  9.0  2.0  21.0    2.0    2.0      NaN   \n",
      "\n",
      "   ...   C09  Descripción  Unnamed: 3 Unnamed: 4  Unnamed: 5 Unnamed: 6  \\\n",
      "0  ...   2.0          NaN         NaN        NaN         NaN        NaN   \n",
      "1  ...  14.0          NaN         NaN        NaN         NaN        NaN   \n",
      "2  ...  12.0          NaN         NaN        NaN         NaN        NaN   \n",
      "3  ...  14.0          NaN         NaN        NaN         NaN        NaN   \n",
      "4  ...  12.0          NaN         NaN        NaN         NaN        NaN   \n",
      "\n",
      "   Unnamed: 7  Unnamed: 8 Unnamed: 9 Unnamed: 10  \n",
      "0         NaN         NaN        NaN         NaN  \n",
      "1         NaN         NaN        NaN         NaN  \n",
      "2         NaN         NaN        NaN         NaN  \n",
      "3         NaN         NaN        NaN         NaN  \n",
      "4         NaN         NaN        NaN         NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Datos guardados exitosamente en 'F6 MPP_archivo_unificado_Paola.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo Excel\n",
    "file_path = 'DATA_MPP/Paola/MPP Colombia F6.xlsx'\n",
    "\n",
    "# Cargar todas las hojas de un archivo Excel en un diccionario de DataFrames\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Leer la primera hoja como base (supongamos que tiene los valores principales de 'nombre_x')\n",
    "df_base = pd.read_excel(file_path, sheet_name=xls.sheet_names[0])\n",
    "\n",
    "# Nombre de la columna que será usada como referencia (la que contiene el código común)\n",
    "columna_codigo = 'C01'\n",
    "\n",
    "# Iterar sobre las demás hojas para hacer el merge usando la columna 'nombre_x'\n",
    "for hoja in xls.sheet_names[1:]:\n",
    "    # Leer cada hoja\n",
    "    df_hoja = pd.read_excel(file_path, sheet_name=hoja)\n",
    "    \n",
    "    # Unificar con la hoja base usando la columna en común ('nombre_x')\n",
    "    df_base = pd.merge(df_base, df_hoja, on=columna_codigo, how='outer')\n",
    "\n",
    "# Mostrar los primeros registros del DataFrame unificado\n",
    "print(df_base.head())\n",
    "\n",
    "# Guardar los datos unificados en un nuevo archivo Excel\n",
    "df_base.to_excel('F6 MPP_archivo_unificado_Paola.xlsx', index=False)\n",
    "\n",
    "print(\"Datos guardados exitosamente en 'F6 MPP_archivo_unificado_Paola.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIFICAR DATOS DE DIGITADORAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los archivos se han combinado y ordenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los dos archivos Excel\n",
    "archivo1 = 'F6 MPP_archivo_unificado_Paola.xlsx'\n",
    "archivo2 = 'F6 MPP_archivo_unificado_Katherine.xlsx'\n",
    "\n",
    "df1 = pd.read_excel(archivo1)\n",
    "df2 = pd.read_excel(archivo2)\n",
    "\n",
    "# Agregar una columna que identifique el archivo de origen\n",
    "df1['Digitadora'] = 'Paola Estefania osorio velasquez'\n",
    "df2['Digitadora'] = 'Leidy Katherine Gonzalez Garzon'\n",
    "\n",
    "# Combinar ambos DataFrames\n",
    "df_combinado = pd.concat([df1, df2])\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "df_combinado.to_excel('F6 archivo_digitadoras_2023.xlsx', index=False)\n",
    "\n",
    "print(\"Los archivos se han combinado y ordenado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REEMPLAZAR DATOS DE AUXILIARES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo que contiene los datos que deseas reemplazar\n",
    "ruta_excel_datos = 'F2 archivo_actualizado_2023.xlsx'  # Cambia con la ruta del archivo con los datos a modificar\n",
    "pestaña_datos = 'Sheet1'  # Cambia con el nombre de la pestaña\n",
    "\n",
    "# Cargar el archivo que contiene los valores para el reemplazo\n",
    "ruta_excel_reemplazo = 'DATA_MPP/F2_AUX.xlsx'  # Cambia con la ruta del archivo con los valores de reemplazo\n",
    "pestaña_reemplazo = 'C21-Presentación'  # Cambia con el nombre de la pestaña\n",
    "\n",
    "# Leer los archivos de Excel\n",
    "df_datos = pd.read_excel(ruta_excel_datos, sheet_name=pestaña_datos)\n",
    "df_reemplazo = pd.read_excel(ruta_excel_reemplazo, sheet_name=pestaña_reemplazo)\n",
    "\n",
    "# Definir las columnas en ambos archivos\n",
    "columna_a_reemplazar = 'C021'  # Cambia con el nombre de la columna donde se hará el reemplazo en df_datos\n",
    "columna_original = 'ID'  # Cambia con el nombre de la columna de referencia en df_reemplazo\n",
    "columna_nueva = 'Valor'  # Cambia con el nombre de la columna que contiene los nuevos valores en df_reemplazo\n",
    "\n",
    "# Crear un diccionario de reemplazo basado en los valores del archivo de reemplazo\n",
    "diccionario_reemplazo = pd.Series(df_reemplazo[columna_nueva].values, index=df_reemplazo[columna_original]).to_dict()\n",
    "\n",
    "# Reemplazar los valores en el archivo de datos\n",
    "df_datos[columna_a_reemplazar] = df_datos[columna_a_reemplazar].replace(diccionario_reemplazo)\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "df_datos.to_excel('F2 archivo_actualizado_2023.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORGANIZAR DATOS DE ACUERDO A LA BASE DE SURVEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar ambos archivos Excel\n",
    "archivo_origen = 'F2 archivo_actualizado_2023.xlsx'  # Archivo con las columnas a trasladar\n",
    "archivo_destino = 'F2_MPP-archivo_integrado_Target.xlsx'  # Archivo donde quieres trasladar la información\n",
    "\n",
    "# Leer los archivos Excel\n",
    "df_origen = pd.read_excel(archivo_origen)\n",
    "df_destino = pd.read_excel(archivo_destino)\n",
    "\n",
    "# Diccionario que mapea las columnas del archivo origen con las del archivo destino\n",
    "# La clave es la columna en el archivo origen y el valor es la columna en el archivo destino\n",
    "mapeo_columnas = {\n",
    "    'C01': 'No Registro',\n",
    "    'Digitadora': 'Digitadora',\n",
    "    'C03': 'Nombre Colector',\n",
    "    'C04': 'Municipio',\n",
    "    'C05': 'Sitio de Desembarco',\n",
    "    'C06': 'Zona de pesca',\n",
    "    'C08': 'Profundidad en Metros',\n",
    "    'C09': 'Sitio Costero de Referencia',\n",
    "    'C10': 'Nombre del Pescador',\n",
    "    'C11': 'Nombre Embarcacion',\n",
    "    'C13': 'Metodo de Propulsion',\n",
    "    'C14': 'Numero de Pescadores',\n",
    "    ('C15.1','C15.2','C15.3','C16'): 'Fecha y Hora de Salida',\n",
    "    ('C17.1','C17.2','C17.3','C18'): 'Fecha y Hora de Llegada',\n",
    "    'C12': 'Tipo de Embarcaciones',\n",
    "    'columna_origen_1': 'Tipo de Arte',\n",
    "    'C19.1.5': 'Metodo de Pesca',\n",
    "    'C19.1.1': 'Longitud (m)',\n",
    "    'C19.1.2': 'Alt. (No de Mallas)',\n",
    "    'C19.1.3': 'TM Min (Pulg)',\n",
    "    'C19.1.4': 'TM Max (Pulg)',\n",
    "    'C19.2.5': 'Metodo de Pesca.1',\n",
    "    'C19.2.1': 'Cant. Anzuelos.',\n",
    "    'C19.2.2': 'No Lances.',\n",
    "    'C19.2.3': 'Tipo de Calibre Min',\n",
    "    'C19.2.4': 'Tipo Calibre Max.',\n",
    "    'C19.3.4': 'Metodo de Pesca.2',\n",
    "    'C19.3.1': 'Cant. Anzuelos..1',\n",
    "    'C19.3.2': 'Tipo de Calibre Min.1',\n",
    "    'C19.3.3': 'Tipo Calibre Max..1',\n",
    "    'C19.4.2': 'No',\n",
    "    'C19.4.3': 'Altura (Radio)',\n",
    "    'C19.4.1': 'TM (Pulg)',\n",
    "    ('C19.5.1','C19.5.2','C19.5.3'): 'TM Copo (Pulg)',\n",
    "    'C19.7.1': 'TM Copo (Pulg).1',\n",
    "    'C19.8.1': 'Cantidad',\n",
    "    'C19.9.1': 'Cantidad.1',\n",
    "    'C19.10.1': 'Cantidad.2',\n",
    "    'C19.11.1': 'Metodo de Pesca.4',\n",
    "    'C19.11.2': 'Cantidad.3',\n",
    "    'columna_origen_1': 'Metodo de Pesca.5',\n",
    "    'C08.19.1': 'Cantidad.4',\n",
    "    'columna_origen_3': 'Metodo de Pesca.6',\n",
    "    'columna_origen_3': 'Long. (m)',\n",
    "    'columna_origen_3': 'TM Copo (Pulg).2',\n",
    "    'columna_origen_3': '(+) Total Valor del Desembarco (COP)',\n",
    "    'columna_origen_3': 'Combustible (COP)',\n",
    "    'columna_origen_3': 'Hielo (COP)',\n",
    "    'columna_origen_3': 'Lonche (COP)',\n",
    "    'columna_origen_3': 'Artes (COP)',\n",
    "    'columna_origen_3': 'Carnada (COP)',\n",
    "    'columna_origen_3': 'Otros (COP)',\n",
    "    'columna_origen_3': '(-) Costo Total (COP)',\n",
    "    'columna_origen_1': 'Total Peso (Kg)',\n",
    "    'columna_origen_2': 'Cant. Especies Desembarcadas',\n",
    "    'columna_origen_3': 'Peso Promedio (Kg)',\n",
    "    'C020': 'Especies',\n",
    "    'C021': 'Presentacion',\n",
    "    'C022': 'Categoria',\n",
    "    'C023': 'No ejemplares',\n",
    "    'C024': 'Peso (Kg)',\n",
    "    'C025': 'Valor de Desembarco ($ Pesos)',\n",
    "    # Añade más columnas si es necesario\n",
    "}\n",
    "\n",
    "# Diccionario para el mapeo condicional entre varias columnas de destino\n",
    "# Cada clave del diccionario contiene una columna de destino a verificar y su columna destino para asignar el valor\n",
    "condicional_destino = {\n",
    "    'columna_destino_a_verificar_1': {\n",
    "        'columna_asignar': 'columna_destino_condicional_1',\n",
    "        'valor': 'Valor asignado si columna_destino_a_verificar_1 está llena'\n",
    "    },\n",
    "    'columna_destino_a_verificar_2': {\n",
    "        'columna_asignar': 'columna_destino_condicional_2',\n",
    "        'valor': 'Otro valor asignado si columna_destino_a_verificar_2 está llena'\n",
    "    },\n",
    "    # Agrega más columnas aquí si lo necesitas\n",
    "}\n",
    "\n",
    "# Condicional que establece el valor de 'Metodo de Pesca.3' según las columnas C17.1, C17.2, C17.3\n",
    "def aplicar_condicional_metodo_pesca(row):\n",
    "    if pd.notna(row['C19.5.1']):  # Verifica si existe algún valor en C17.1\n",
    "        return 'Cam'\n",
    "    elif pd.notna(row['C19.5.2']):  # Verifica si existe algún valor en C17.2\n",
    "        return 'Velao'\n",
    "    elif pd.notna(row['C19.5.3']):  # Verifica si existe algún valor en C17.3\n",
    "        return 'Jal'\n",
    "    else:\n",
    "        return None  # Devolver None si no hay valores en ninguna columna\n",
    "\n",
    "    \n",
    "# Bucle para recorrer el diccionario y trasladar la información\n",
    "for columnas_origen, columna_destino in mapeo_columnas.items():\n",
    "    if isinstance(columnas_origen, tuple):  # Si es un conjunto de columnas para combinar\n",
    "        # Combinar las columnas de Día, Mes, Año con un separador (por ejemplo, \"-\")\n",
    "        df_destino[columna_destino] = df_origen[list(columnas_origen)].astype(str).agg('-'.join, axis=1)\n",
    "    else:  # Si es una columna simple\n",
    "        if columnas_origen in df_origen.columns and columna_destino in df_destino.columns:\n",
    "            # Transferir los datos de la columna origen a la columna destino\n",
    "            df_destino[columna_destino] = df_origen[columnas_origen]\n",
    "        else:\n",
    "            print(f\"Una de las columnas '{columnas_origen}' o '{columna_destino}' no existe en los archivos.\")\n",
    "\n",
    "# Sobrescribir el archivo destino con las nuevas modificaciones\n",
    "df_destino.to_excel(archivo_destino, index=False)\n",
    "\n",
    "# Aplicar el condicional para 'Metodo de Pesca.3' basado en las columnas C17.1, C17.2, C17.3\n",
    "df_destino['Metodo de Pesca.3'] = df_origen.apply(aplicar_condicional_metodo_pesca, axis=1)\n",
    "\n",
    "print(f'La información ha sido actualizada exitosamente en el archivo \"{archivo_destino}\".')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
